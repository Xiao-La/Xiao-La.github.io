---
layout: post
title: 使用Python写一个成语接龙工具
categories: python
description: python
keywords: python,pypinyin,成语接龙,一个顶俩,接龙红包,成语词典
---






# Python网络爬虫入门
---
来讲一下**怎么入门Python爬虫**。

### 爬虫是什么?

想象你需要收集十大最受欢迎的编程语言的变化趋势，你点开了一个拥有**海量数据**的网页，里面用表格写出了近几年每个月的每个编程语言的受欢迎指数。

如果手动记录表格数据，再画成折线图，恐怕你会疯掉。

事实上，爬虫就是**模拟浏览器请求网页**，**自动采集** 网页上的数据。你可以用这些已经格式化、保存在本地的数据，再用于他处。
>搜索引擎就是一个不断运行的爬虫系统。
### 为什么要用Python写爬虫?  

- `Python`拥有强大的爬虫第三方库。
- `Python`拥有方便的爬虫框架。
- **开发效率高**，虽然运行效率不如编译型语言，但是爬虫你还想要多线程高并发?

### 我应该学习哪些方面的内容?

不必担心你学不会下列内容，**它们都很简单**，下文中我们会进行介绍。

- 必须:
 - 学会抓包、了解基本HTML语法
 - 网络请求的类型与基本参数
 - 了解不触犯法律的爬虫知识
 - 一个适合你的爬虫第三方库
 - 一个适合你的信息提取方法
 - 一个适合你的数据处理方法
- 建议:
 - 了解网络请求协议
 - 使用模块化、错误处理完善的代码
 - 学习正则表达式、XPath、Beautiful Soup等常用处理网页方式
 - 学习 Panda、Numpy 等数据处理方式
 - 学习 Matplotlib 等数据可视化库

注 : 这些**并不是你必须要学习的**(其中许多模块我也不了解)，当你需要时再去学习(甚至套用)也不迟。

### 我应该怎么开始?

下图是简化后的浏览器访问一个网页的流程:
![img](\images\htl.png)

所以，爬虫就要伪造其中发送请求的部分，并且获取相应的响应。

实际上，Requests库已经**封装好了这一切**，等着你调用。

网络请求常用的类型是**Get**和**Post**，你的浏览器发送的默认是Get请求。Post请求的作用是在请求中附带信息，比如你从B站的主站跳转到另一个页面，你会看到URL的问号后面里多了些东西，这些就是附带的内容。

现在，打开你的终端，打开Python，输入如下内容:
```python
import requests # 导入reuqests库
url = "https://www.baidu.com/" #str:url
r = requests.get(url) #调用requests库的get方法，使用GET 请求url
print(r.text)#r.text就是返回的HTML内容
```
屏幕上输出的就是百度首页的源代码了。

这就是为什么我们要用`Python`写爬虫，它实在太简单了。

现在，你可以去学习Requests这个库了，点开你的搜索引擎，搜索 `python3 requests` ，你会看到通俗易懂的教程。
### 现在我会得到网页的响应了，那么如何处理这些杂乱的源代码?

你可以使用主流的几种办法:
**正则表达式**、**Xpath**或**Beautiful Soup** 来提取网页中的元素。

下列是这些方法的优缺点:

| 方法  |    优点    |      缺点    |  
| ----- | :-------- | :---------   |
| 正则表达式|简洁，应用范围广，简单|不是处理网页的最好方法，稍微慢于Xpath|
| Xpath|简洁，方便(可以直接生成)，速度快|学习成本略高|
| Beautiful Soup|可读性高，极其易学|稍微慢于Xpath|

我个人推荐你先学习正则表达式和Beautiful Soup。
教程:[正则](https://www.runoob.com/regexp/regexp-tutorial.html)、[Xpath](https://www.runoob.com/xpath/xpath-tutorial.html)、[Beautifulsoup](https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/)

### 我得到了数据，那怎么把数据画成图?
你可以学习Matplotlib、Plotly等数据可视化包，同样的，你可以搜索`python3 matplotlib`来学习。

### 如何进阶?
网站显然不会公开让你爬他们辛辛苦苦收集来的数据，一般都会设计各种各样的反爬虫机制。(当然，如果你将数据用做商用就是犯法的)

实际上，你可以通过大量的实战来解决这个问题——网站反爬的机制没那么多，你甚至可以暴力破解——用`selenium`直接用浏览器作为爬虫——虽然并不推荐常用这种办法。

你可以搜索`python3 爬虫案例`来获得相关的案例，尝试将它们读懂，或者再次写一遍，甚至优化别人的代码，你会逐渐变好的。

共勉。
